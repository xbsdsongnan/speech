# 基于DNN-HMM的语音识别系统作业

本次课程共有2个作业，分别如下所示。

## 作业1

### 数据说明
本次实验所用的数据为0-9（其中0的标签为Z（Zero））和O这11个字符的英文录音所提取的39维的MFCC特征。其中
* 训练数据：330句话，11个字符，每个字符30句话，训练数据位于train目录下。
* 测试数据：110句话，11个字符，每个字符10句话，测试数据位于test目录下。

train/test目录下各有3个文件，分别如下：
* text: 标注文件，每一行第一列为句子id，第二列为标注。
* feats.scp: 特征索引文件，每一行第一列为句子id，第二列为特征的索引表示。
* feats.ark: 特征实际存储文件，该文件为二进制文件。

### 实验内容
本实验实现了一个简单的DNN的框架，使用DNN进行11个数字的训练和识别。
实验中使用以上所述的训练和测试数据分别对该DNN进行训练和测试。
请阅读dnn.py中的代码，理解该DNN框架，完善ReLU激活函数和FullyConnect全连接层的前向后向算法。
可以参考Softmax的前向和后向实现。dnn.py中代码插入位置为。
``` python
# BEGIN_LAB
# write your code here
# END_LAB
```

### 运行和检查

使用如下命令运行该实验，该程序末尾会打印出在测试集上的准确率。假设实现正确，应该得到95%以上的准确率，作者的实现分类准确率为98.18%。

``` sh
python dnn.py
```

### 拓展
除了跑默认参数之外，读者还可以自己尝试调节一些超参数，并观察这些超参数对最终准确率的影响。如
* 学习率
* 隐层结点数
* 隐层层数

读者还可以基于该框架实现神经网络中的一些基本算法，如：
* sigmoid和tanh激活函数
* dropout
* L2 regularization
* optimizer(Momentum/Adam)
* ...

实现后读者可以在该数字识别任务上应用这些算法，并观察对识别率的影响。

通过调节这些超参数和实现其他的一些基本算法，读者可以进一步认识和理解神经网络。

## 作业2

基于Kaldi理解基于DNN-HMM的语音识别系统。请安装kaldi，并运行kaldi下的标准数据集THCHS30的实验，该实验如链接所示， 
https://github.com/kaldi-asr/kaldi/blob/master/egs/thchs30/s5/run.sh。

[THCHS30](http://www.openslr.org/18/)是清华大学开源的一个中文数据集，总共30小时。请基于该数据集，基于kaldi下该数据集的标注脚本，梳理基于DNN-HMM的语音识别系统的**流程，其有哪些步骤，每一步的输入、输出，步骤间的相互关系**等，可以把自己的理解流程化、图形化、文字化的记录下来，写下来。
